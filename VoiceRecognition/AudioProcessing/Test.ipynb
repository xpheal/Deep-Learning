{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some functions for audio visualization\n",
    "\n",
    "# Plot the <num_samples> of audio signal <x>\n",
    "def plot_wave(x, num_samples):\n",
    "    y = x[:num_samples]\n",
    "    \n",
    "    x = np.arange(num_samples)\n",
    "    x = x/44100\n",
    "    \n",
    "    plt.title(\"Amplitude versus Time(Samples)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.xlabel(\"Time(Samples)\")\n",
    "    plt.plot(x,y)\n",
    "    plt.show()\n",
    "    \n",
    "# Plot the results of STFT on time series <x> in decibels\n",
    "def plot_db_scaled_spectogram(x, num_samples, n_fft=2048, hop_length=512):\n",
    "    x = x[:num_samples]\n",
    "    \n",
    "    D = librosa.stft(x, n_fft=n_fft, hop_length=hop_length)\n",
    "    half = D.shape[0] // 2\n",
    "    D = D[:half]\n",
    "    \n",
    "    D = librosa.amplitude_to_db(D, ref=np.max)\n",
    "    \n",
    "    librosa.display.specshow(D, y_axis='linear')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('DB spectogram')\n",
    "    plt.show()\n",
    "\n",
    "# Similar to the function above, uses logarithmic scale for the y axis\n",
    "def plot_log_db_scaled_spectogram(x, num_samples, n_fft=2048, hop_length=512):\n",
    "    x = x[:num_samples]\n",
    "\n",
    "    D = librosa.amplitude_to_db(librosa.stft(x, n_fft=n_fft, hop_length=hop_length), ref=np.max)\n",
    "    librosa.display.specshow(D, y_axis='log')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('DB spectogram')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_db(D):\n",
    "    librosa.display.specshow(D, y_axis='linear')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('DB spectogram')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Journal\n",
    "1) By using window_size(n_fft) of 0.25s(sample_rate // 4) and hop_length = n_fft // 4, we can get an accuracy of around 90% for predicting 6 classes. The number of training examples affect the accuracy. 100 examples per speaker is good.\n",
    "\n",
    "# Things that can be done\n",
    "1) Cut the frequencies by half after FFT because you don't actually need the top few frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dir = \"./LibriSpeech/test-clean\"\n",
    "examples = [] # To store examples\n",
    "sample_rate = 44100 # Control sampling rate\n",
    "n_fft = sample_rate // 4 # We are going to use 0.25s as the window\n",
    "hop_length = n_fft // 4 # Hop_length is default which is n_fft // 4\n",
    "num_examples_per_speaker = 200 # Number of samples to get for each speaker\n",
    "use_decibel = False # Use decibel instead of magnitude if this is set to true\n",
    "num_class = 6 # Number of speakers to used, must be smaller than number of possible speakers\n",
    "seconds_per_example = 1\n",
    "silence_threshold = 0.01 # If the amplitude in the time series does not exceed this threshold, it is not included in the examples\n",
    "frequency_threshold = n_fft * 3 // 16 # A threshold calculated by checking the mean and max of STFT result\n",
    "# frequency_threshold = n_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert a time series into multiple smaller examples\n",
    "def convert_series_to_multiple_examples(x, label):\n",
    "    D = librosa.stft(x, n_fft=n_fft, hop_length=hop_length)\n",
    "    D = D[:frequency_threshold]\n",
    "    \n",
    "    if use_decibel:\n",
    "        # Use decibel\n",
    "        D = librosa.amplitude_to_db(D, ref=np.max)\n",
    "    else:\n",
    "        # Use magnitude\n",
    "        D = np.abs(D)\n",
    "    \n",
    "    D = np.transpose(D)\n",
    "    D = np.insert(D, D.shape[1], label, 1)\n",
    "\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert a time series into an example\n",
    "def convert_series_to_example(x, label):\n",
    "    D = librosa.stft(x, n_fft=n_fft, hop_length=hop_length)\n",
    "    D = D[:frequency_threshold]\n",
    "\n",
    "    if use_decibel:\n",
    "        # Use decibel\n",
    "        D = librosa.amplitude_to_db(D, ref=np.max)\n",
    "    else:\n",
    "        # Use magnitude\n",
    "        D = np.abs(D)\n",
    "    \n",
    "    # Calculate and plot mean and max of STFT result\n",
    "#     length =  len(D) // 16\n",
    "    \n",
    "#     plot_db(D)\n",
    "    \n",
    "#     i = 0\n",
    "#     for _ in range(8):\n",
    "#         print(\"Quarter {}\".format(_))\n",
    "#         k = D[i:i+length]\n",
    "#         print(np.mean(k))\n",
    "#         print(np.amax(k))\n",
    "#         i += length\n",
    "\n",
    "    D = np.ndarray.flatten(D)\n",
    "    D = np.append(D, label)\n",
    "#     D = np.transpose(D)\n",
    "#     D = np.insert(D, D.shape[1], label, 1)\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 1 done\n",
      "Speaker 2 done\n",
      "Speaker 3 done\n",
      "Speaker 4 done\n",
      "Speaker 5 done\n",
      "Speaker 6 done\n"
     ]
    }
   ],
   "source": [
    "num_speakers = 0\n",
    "for speaker_id in listdir(test_dir):\n",
    "    # Loop through each speaker\n",
    "    label = int(speaker_id)\n",
    "    num_examples = 0\n",
    "    curr_examples = []\n",
    "\n",
    "    if num_speakers >= num_class:\n",
    "        break\n",
    "    \n",
    "    for books in listdir(test_dir + \"/\" + speaker_id):\n",
    "        # Loop through each books for speaker_id\n",
    "        for audio_files in listdir(test_dir + \"/\" + speaker_id + \"/\" + books):\n",
    "            # Loop through each audio for that book\n",
    "            \n",
    "            if audio_files.split('.')[1] != 'flac':\n",
    "                # Check if its a flac file\n",
    "                continue\n",
    "            \n",
    "            # Load time series\n",
    "            file_name = test_dir + \"/\" + speaker_id + \"/\" + books + \"/\" + audio_files\n",
    "            time_series, rate = librosa.load(file_name, sr=sample_rate)\n",
    "            \n",
    "            duration = len(time_series) // sample_rate\n",
    "            \n",
    "            sample_time_series = []\n",
    "            \n",
    "            hop_per_example = int(sample_rate * seconds_per_example)\n",
    "            num_loops = int(duration // seconds_per_example)\n",
    "            \n",
    "            # First method\n",
    "            start = 0\n",
    "            for _ in range(num_loops):\n",
    "                extracted = time_series[start:start + hop_per_example]\n",
    "                \n",
    "                if max(extracted) > silence_threshold:\n",
    "                    sample_time_series += [extracted]\n",
    "                    \n",
    "                start += hop_per_example\n",
    "                            \n",
    "            for i in sample_time_series:\n",
    "                curr_examples.append(convert_series_to_example(i, label))\n",
    "                num_examples += 1\n",
    "                \n",
    "                if num_examples >= num_examples_per_speaker:\n",
    "                    break\n",
    "            \n",
    "            # Second method\n",
    "#             curr_examples += convert_time_series_to_multiple_examples(time_series, label)\n",
    "#             num_examples += D.shape[0]\n",
    "    \n",
    "            if num_examples >= num_examples_per_speaker:\n",
    "                break\n",
    "            \n",
    "        if num_examples >= num_examples_per_speaker:\n",
    "            # Stop for the outer loop        \n",
    "            break\n",
    "    \n",
    "    # Second method\n",
    "#     C = np.concatenate(curr_examples)\n",
    "#     examples += [C[:num_examples_per_speaker]]        \n",
    "\n",
    "    # First method\n",
    "    examples += curr_examples\n",
    "    num_speakers += 1\n",
    "    print(\"Speaker {} done\".format(num_speakers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 35140)\n"
     ]
    }
   ],
   "source": [
    "# E = np.concatenate(examples)\n",
    "E = np.array(examples)\n",
    "np.random.shuffle(E)\n",
    "print(E.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Old code\n",
    "# num_class_to_predict = 6 # Number of speakers to used, must be smaller than num_speakers\n",
    "\n",
    "# np.random.shuffle(examples) # Shuffle the speakers before extracting\n",
    "# E = np.concatenate(examples[:num_class_to_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_size: 1080\n",
      "Testing_size: 120\n"
     ]
    }
   ],
   "source": [
    "training_size = len(E) * 90 // 100\n",
    "testing_size = len(E) - training_size\n",
    "print(\"Training_size: {}\\nTesting_size: {}\".format(training_size, testing_size))\n",
    "\n",
    "np.random.shuffle(E)\n",
    "train = E[:training_size]\n",
    "test = E[training_size:]\n",
    "\n",
    "features_train = train[:,:-1]\n",
    "labels_train = train[:,-1]\n",
    "\n",
    "features_test = test[:,:-1]\n",
    "labels_test = test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 14.86042987\n",
      "Validation score: 0.287037\n",
      "Iteration 2, loss = 8.97531327\n",
      "Validation score: 0.574074\n",
      "Iteration 3, loss = 2.77990311\n",
      "Validation score: 0.814815\n",
      "Iteration 4, loss = 1.16104590\n",
      "Validation score: 0.814815\n",
      "Iteration 5, loss = 0.43860079\n",
      "Validation score: 0.824074\n"
     ]
    }
   ],
   "source": [
    "# clf = MLPClassifier(early_stopping=True, activation='logistic', hidden_layer_sizes=(100,100), alpha=0.00001, verbose=True)\n",
    "clf = MLPClassifier(early_stopping=True, activation='relu', alpha=1e-06, verbose=True, \n",
    "\tlearning_rate='invscaling', solver='adam', hidden_layer_sizes=(256,128), warm_start=True)\n",
    "clf.fit(features_train, labels_train) \n",
    "print(\"Accuracy: {}\".format(clf.score(features_test, labels_test)))\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Configuration\n",
    "early_stopping=True, activation='relu', alpha=1e-06, verbose=True, learning_rate='invscaling', solver='adam', hidden_layer_sizes=(256,128), warm_start=True\n",
    "\n",
    "Using warm start, which means that the previous trained classifier is used instead of starting it from scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(early_stopping=True, activation='relu', alpha=1e-06, verbose=True, \n",
    "        solver='adam', hidden_layer_sizes=(256,128), warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(early_stopping=True, activation='relu', alpha=1e-06, verbose=False, \n",
    "        solver='adam', hidden_layer_sizes=(256), warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scores, valid_scores = validation_curve(clf, features_train, labels_train, \"hidden_layer_sizes\", [(2**i) for i in range(11)], verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "title = \"Number of Hidden Units Versus Accuracy\\n1 Hidden Layer Neural Network\"\n",
    "plt.title(title)\n",
    "\n",
    "plt.xlabel(\"Number of Hidden Units\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "train_sizes_abs = [(2**i) for i in range(11)]\n",
    "\n",
    "plt.fill_between(train_sizes_abs, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes_abs, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes_abs, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes_abs, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "# plt.show()\n",
    "\n",
    "f.savefig(\"hidden_units_one_layer_10_speakers.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For storing stuff, don't simply run this\n",
    "# speakers_x = x\n",
    "# speakers_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# f = plt.figure()\n",
    "plt.title(\"Number of Speakers Classified vs Accuracy\")\n",
    "plt.xlabel(\"Number of Speakers Classified\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "\n",
    "plt.plot(x, y, '.')\n",
    "plt.plot(x, m * x + b, '-')\n",
    "# plt.show()\n",
    "\n",
    "f.savefig(\"speakers_acc.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "title = \"Learning Curve Classifying 10 Speakers\"\n",
    "plt.title(title)\n",
    "\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.fill_between(train_sizes_abs, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes_abs, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes_abs, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes_abs, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "f.savefig(\"learning_curve_20_speakers.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
